{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846a547e-0fe5-4d17-94f9-7b9641ff7b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "print(torch.__version__, torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4367ea1-bb66-4da4-8a5a-dcc36b0bee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makeState ----------------------------------------------------------------------------------------------------------- #\n",
    "\n",
    "def makeState(state1_mean, state2_mean, state3_mean, state4_mean, state_length, n_data, dim):\n",
    "    dataLength = state_length * 4\n",
    "    data = np.zeros((n_data, dataLength, dim))\n",
    "    for i in range(n_data):\n",
    "        state = np.zeros((dataLength, dim))\n",
    "        for j in range(dim):\n",
    "            sd_low = 0.01\n",
    "            sd_high = 0.03\n",
    "            state_tmp = np.zeros((dataLength, 1))\n",
    "            state1 = np.random.normal(loc=state1_mean, scale=np.random.uniform(low=0.1, high=0.2), size=state_length).astype(np.float32)\n",
    "            state2 = np.random.normal(loc=state2_mean, scale=np.random.uniform(low=0.1, high=0.2), size=state_length).astype(np.float32)\n",
    "            state3 = np.random.normal(loc=state3_mean, scale=np.random.uniform(low=0.1, high=0.2), size=state_length).astype(np.float32)\n",
    "            state4 = np.random.normal(loc=state4_mean, scale=np.random.uniform(low=sd_low, high=sd_high), size=state_length).astype(np.float32)\n",
    "            state_tmp = np.concatenate([state1, state2, state3, state4])\n",
    "            state[:, j] = state_tmp.copy()\n",
    "        data[i, :, :] = state.copy()\n",
    "    return(data)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------- #\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# makeDataset ----------------------------------------------------------------------------------------------------------------- #\n",
    "\n",
    "# many to many data\n",
    "# def make_dataset(low_data, label, data_length):\n",
    "\n",
    "#     data, target = [], []\n",
    "\n",
    "#     for i in range(len(low_data)-data_length):\n",
    "#         data.append(low_data[i:i + data_length])\n",
    "#         target.append(label[i + data_length])\n",
    "\n",
    "#     re_data = np.array(data).reshape(len(data), data_length, low_data.shape[1])\n",
    "#     re_target = np.array(target).reshape(len(data), label.shape[1])\n",
    "\n",
    "#     return re_data, re_target\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------------------- #\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train dataset -------------------------------------------------------------------------------------------------------- #\n",
    "# parameter\n",
    "dataLength = 100 # 系列長\n",
    "n_state = 4 #状態数（固定）\n",
    "state_length = int(dataLength / n_state) #1つのstateの長さ\n",
    "n_data = 25 #1つのクラスのデータ数\n",
    "dim = 1 #特徴量数\n",
    "classNum = 4\n",
    "\n",
    "# class0\n",
    "state1_mean = 0.5 #state1の平均\n",
    "state2_mean = 0.5 #state2の平均\n",
    "state3_mean = 0.5 #state3の平均\n",
    "state4_mean = 0.2 #state4の平均\n",
    "x_0 = makeState(state1_mean, state2_mean, state3_mean, state4_mean, state_length, n_data, dim)\n",
    "y_0 = np.full(n_data, 0, dtype = np.int64) # many to one\n",
    "# y_0 = np.full(n_data*data_length, 0) # many to many \n",
    "\n",
    "# class1\n",
    "state1_mean = 0.5 #state1の平均\n",
    "state2_mean = 0.5 #state2の平均\n",
    "state3_mean = 0.5 #state3の平均\n",
    "state4_mean = 0.4 #state4の平均\n",
    "x_1 = makeState(state1_mean, state2_mean, state3_mean, state4_mean, state_length, n_data, dim)\n",
    "y_1 = np.full(n_data, 1, dtype = np.int64)\n",
    "# y_1 = np.full(n_data*data_length, 1)\n",
    "\n",
    "# class2\n",
    "state1_mean = 0.5 #state1の平均\n",
    "state2_mean = 0.5 #state2の平均\n",
    "state3_mean = 0.5 #state3の平均\n",
    "state4_mean = 0.6 #state4の平均\n",
    "x_2 = makeState(state1_mean, state2_mean, state3_mean, state4_mean, state_length, n_data, dim)\n",
    "y_2 = np.full(n_data, 2, dtype = np.int64)\n",
    "# y_2 = np.full(n_data*data_length, 2)\n",
    "\n",
    "# calss3\n",
    "state1_mean = 0.5 #state1の平均\n",
    "state2_mean = 0.5 #state2の平均\n",
    "state3_mean = 0.5 #state3の平均\n",
    "state4_mean = 0.8 #state4の平均\n",
    "x_3 = makeState(state1_mean, state2_mean, state3_mean, state4_mean, state_length, n_data, dim)\n",
    "y_3 = np.full(n_data, 3, dtype = np.int64)\n",
    "# y_3 = np.full(n_data*data_length, 3)\n",
    "\n",
    "# make train data\n",
    "## x\n",
    "series_length = dataLength * n_data * n_state\n",
    "x = np.concatenate([x_0, x_1, x_2, x_3], axis = 0)#.reshape(series_length, n_feature)\n",
    "## y\n",
    "y = np.concatenate([y_0, y_1, y_2, y_3], axis = 0).reshape(-1, 1)\n",
    "# train_x, train_y = make_dataset(x, y, data_length)\n",
    "\n",
    "# plot\n",
    "color_list = [\"blue\", \"red\", \"green\", \"purple\"]\n",
    "idx = 0\n",
    "for j in range(0, classNum):\n",
    "    plt.figure()\n",
    "    for i in range(0, n_data):\n",
    "        plt.ylim(0.0, 1.0)\n",
    "        plt.plot(x[idx + i], color = color_list[j] )\n",
    "    idx += n_data\n",
    "    plt.title(\"train_data class{}\".format(j))\n",
    "    plt.xlabel(\"time step\")\n",
    "    plt.savefig(\"data7/train_data_class{}.png\".format(j))\n",
    "\n",
    "\n",
    "\n",
    "## shuffle\n",
    "np.random.seed(1234)\n",
    "idx = np.arange(x.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "train_x = x[idx, :, :].copy()\n",
    "train_y = y[idx, :].copy()\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------- #\n",
    "\n",
    "# test dataset -------------------------------------------------------------------------------------------------------- #\n",
    "# parameter\n",
    "# data_length = 20 # 系列長\n",
    "# n_state = 4 #状態数（固定）\n",
    "# state_length = int(data_length / n_state) #1つのstateの長さ\n",
    "# n_data = 5 #1つのクラスのデータ数\n",
    "# n_feature = 1 #特徴量数\n",
    "\n",
    "# class0\n",
    "state1_mean = 0.5 #state1の平均\n",
    "state2_mean = 0.5 #state2の平均\n",
    "state3_mean = 0.5 #state3の平均\n",
    "state4_mean = 0.2 #state4の平均\n",
    "x_0 = makeState(state1_mean, state2_mean, state3_mean, state4_mean, state_length, n_data, dim)\n",
    "y_0 = np.full(n_data, 0, dtype = np.int64) # many to one\n",
    "# y_0 = np.full(n_data*data_length, 0) # many to many \n",
    "\n",
    "# class1\n",
    "state1_mean = 0.5 #state1の平均\n",
    "state2_mean = 0.5 #state2の平均\n",
    "state3_mean = 0.5 #state3の平均\n",
    "state4_mean = 0.4 #state4の平均\n",
    "x_1 = makeState(state1_mean, state2_mean, state3_mean, state4_mean, state_length, n_data, dim)\n",
    "y_1 = np.full(n_data, 1, dtype = np.int64)\n",
    "# y_1 = np.full(n_data*data_length, 1)\n",
    "\n",
    "# class2\n",
    "state1_mean = 0.5 #state1の平均\n",
    "state2_mean = 0.5 #state2の平均\n",
    "state3_mean = 0.5 #state3の平均\n",
    "state4_mean = 0.6 #state4の平均\n",
    "x_2 = makeState(state1_mean, state2_mean, state3_mean, state4_mean, state_length, n_data, dim)\n",
    "y_2 = np.full(n_data, 2, dtype = np.int64)\n",
    "# y_2 = np.full(n_data*data_length, 2)\n",
    "\n",
    "# calss3\n",
    "state1_mean = 0.5 #state1の平均\n",
    "state2_mean = 0.5 #state2の平均\n",
    "state3_mean = 0.5 #state3の平均\n",
    "state4_mean = 0.8 #state4の平均\n",
    "x_3 = makeState(state1_mean, state2_mean, state3_mean, state4_mean, state_length, n_data, dim)\n",
    "y_3 = np.full(n_data, 3, dtype = np.int64)\n",
    "# y_3 = np.full(n_data*data_length, 3)\n",
    "\n",
    "# calss3\n",
    "state1_mean = 0.8 #state1の平均\n",
    "state2_mean = 0.5 #state2の平均\n",
    "state3_mean = 0.5 #state3の平均\n",
    "state4_mean = 0.5 #state4の平均\n",
    "x_3 = makeState(state1_mean, state2_mean, state3_mean, state4_mean, state_length, n_data, dim)\n",
    "y_3 = np.full(n_data, 3, dtype = np.int64)\n",
    "# y_3 = np.full(n_data*data_length, 3)\n",
    "\n",
    "# make test data\n",
    "## x\n",
    "series_length = dataLength * n_data * n_state\n",
    "x = np.concatenate([x_0, x_1, x_2, x_3], axis = 0)#.reshape(series_length, n_feature)\n",
    "## y\n",
    "y = np.concatenate([y_0, y_1, y_2, y_3], axis = 0).reshape(-1, 1)\n",
    "# test_x, test_y = make_dataset(x, y, data_length)\n",
    "\n",
    "# plot\n",
    "idx = 0\n",
    "for j in range(0, classNum):\n",
    "    plt.figure()\n",
    "    for i in range(0, n_data):\n",
    "        plt.ylim(0.0, 1.0)\n",
    "        plt.plot(x[idx + i], color = color_list[j] )\n",
    "    idx += n_data\n",
    "    plt.title(\"test_data class{}\".format(j))\n",
    "    plt.xlabel(\"time step\")\n",
    "    plt.savefig(\"data7/test_data_class{}.png\".format(j))\n",
    "\n",
    "## shuffle\n",
    "np.random.seed(12345)\n",
    "idx = np.arange(x.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "test_x = x[idx, :, :].copy()\n",
    "test_y = y[idx, :].copy()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------- #\n",
    "\n",
    "\n",
    "# transform to tensor ----------------------------------------------------------------------------------- #\n",
    "\n",
    "train_x = torch.tensor(train_x, requires_grad=True, dtype = torch.float32)\n",
    "\n",
    "train_y = torch.tensor(train_y, dtype = torch.long)\n",
    "\n",
    "test_x = torch.tensor(test_x, requires_grad=True, dtype = torch.float32)\n",
    "\n",
    "test_y = torch.tensor(test_y, dtype = torch.long)\n",
    "\n",
    "# confirm\n",
    "print(\"train_x:\", train_x.shape)\n",
    "print(\"train_y:\", train_y.shape)\n",
    "print(\"test_x:\", test_x.shape)\n",
    "print(\"test_y:\", test_y.shape)\n",
    "# ------------------------------------------------------------------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d45e1e-7c71-4b31-aa5c-1d95f18bec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class R_LLGMN_Pytorch(nn.Module):\n",
    "    def __init__(self, dim, classNum, stateNum, componentNum, dataLength):\n",
    "        #　変数\n",
    "        self.dim = dim\n",
    "        self.classNum = classNum                        # クラス数\n",
    "        self.stateNum = stateNum                        # 状態数\n",
    "        self.componentNum = componentNum                # コンポーネント数\n",
    "        self.dataLength = dataLength                             # 時系列長\n",
    "        self.logSize = int(1 + dim * (dim + 3) / 2)     # 非線形変換後のベクトル数\n",
    "        # 各層の初期化\n",
    "        self.in1 = torch.ones((self.dataLength, self.logSize), dtype = torch.float32)\n",
    "        self.out1 = torch.zeros((self.dataLength, self.logSize), dtype = torch.float32)\n",
    "        self.in2 = torch.zeros((self.dataLength, self.classNum, self.stateNum, self.stateNum, self.componentNum), dtype = torch.float32)\n",
    "        self.out2 = torch.zeros((self.dataLength, self.classNum, self.stateNum, self.stateNum, self.componentNum), dtype = torch.float32)\n",
    "        self.in3 = torch.zeros((self.dataLength, self.classNum, self.stateNum, self.stateNum), dtype = torch.float32)\n",
    "        self.out3 = torch.zeros((self.dataLength, self.classNum, self.stateNum, self.stateNum), dtype = torch.float32)\n",
    "        self.in4 = torch.zeros((self.dataLength, self.classNum, self.stateNum), dtype = torch.float32)\n",
    "        self.out4 = torch.zeros((self.dataLength, self.classNum, self.stateNum), dtype = torch.float32)\n",
    "        self.in5 = torch.zeros((self.dataLength, self.classNum), dtype = torch.float32)\n",
    "        self.out5 = torch.zeros((self.dataLength, self.classNum), dtype = torch.float32)\n",
    "        \n",
    "        super(R_LLGMN_Pytorch, self).__init__()\n",
    "        # パラメータ\n",
    "        self.weight = nn.Parameter(torch.ones((self.classNum, self.stateNum, self.stateNum, self.componentNum, self.logSize), dtype = torch.float32))\n",
    "      \n",
    "\n",
    "    # 順方向\n",
    "    def forward(self, X):\n",
    "        rho = 1e-5\n",
    "        \n",
    "        for t in range(self.dataLength):\n",
    "            \n",
    "            # ----第1層----\n",
    "            x = X[t].reshape(dim, 1)\n",
    "            a = x @ x.T\n",
    "            \n",
    "            # 1次の項\n",
    "            for i in range(self.dim):\n",
    "                self.in1[t][i+1] = X[t][i]\n",
    "            # 2次の項\n",
    "            for i in range(self.logSize - self.dim - 1):\n",
    "                self.in1[t][i+self.dim+1] = a[np.triu_indices(self.dim)][i]\n",
    "            self.out1[t] = self.in1[t]\n",
    "            # ----第1層----\n",
    "            \n",
    "            for c in range(self.classNum):\n",
    "                for k1 in range(self.stateNum):\n",
    "                    for k in range(self.stateNum):\n",
    "                        for m in range(self.componentNum):\n",
    "                            # ----第2層----\n",
    "                            self.in2[t][c][k1][k][m] = torch.sum(self.weight[c][k1][k][m].clone() * self.out1[t].clone())\n",
    "                            self.out2[t][c][k1][k][m] = torch.exp(self.in2[t][c][k1][k][m].clone())\n",
    "                            # ----第2層----\n",
    "\n",
    "                        # ----第3層----\n",
    "                        self.in3[t][c][k1][k] = torch.sum(self.out2[t][c][k1][k].clone())\n",
    "                        if t == 0:\n",
    "                            self.out3[t] = self.in3[t].clone()\n",
    "                        else:\n",
    "                            self.out3[t][c][k1][k] = self.out4[t-1][c][k1].clone() * self.in3[t][c][k1][k].clone()\n",
    "                        # ----第3層----\n",
    "                    \n",
    "                    # ----第4層----\n",
    "                    self.in4[t][c][k1] = torch.sum(self.out3[t][c][k1].clone())\n",
    "                    \n",
    "            F_NN = torch.sum(self.in4[t].clone())\n",
    "            \n",
    "            if F_NN != 0:\n",
    "                self.out4[t] = self.in4[t].clone() / F_NN\n",
    "            else: # エラー回避\n",
    "                self.out4[t] = self.in4[t].clone() / rho\n",
    "            # ----第4層----\n",
    "            \n",
    "            # ----第5層----\n",
    "            for c in range(self.classNum):\n",
    "                self.in5[t][c] = torch.sum(self.out4[t][c].clone())\n",
    "            \n",
    "            self.in5[t] = torch.sum(self.out4[t].clone(), axis=1)\n",
    "            \n",
    "            self.out5[t] = self.in5[t].clone()\n",
    "            # ----第5層----\n",
    "            y = self.out5[t].clone()\n",
    "            return y\n",
    "\n",
    "\n",
    "dim = dim\n",
    "classNum = 4\n",
    "stateNum = 2\n",
    "componentNum = 2\n",
    "dataLength = dataLength\n",
    "\n",
    "model = R_LLGMN_Pytorch(dim, classNum, stateNum, componentNum, dataLength)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ec4650-29fa-4fc0-a9fd-e0d1b241c508",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "loss_record = []\n",
    "epochs = 10\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for j, (X, label) in enumerate(zip(train_x, train_y)):\n",
    "        y = model(X).view(-1, classNum)\n",
    "        loss = loss_function(y, label)\n",
    "        # print(\"time:{}, loss:{}\".format(j, loss))\n",
    "        running_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "    running_loss /= j+1\n",
    "    loss_record.append(running_loss)\n",
    "    print(\"epoch:\", epoch, \"\\t\", \"loss:\", running_loss)\n",
    "print(\"done.\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(loss_record)\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.title(\"CrossEntropyLoss\")\n",
    "plt.savefig(\"data7/loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22dbe57-14df-424a-8480-17de9ffd2c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "predict_list = np.ones(len(test_y))\n",
    "answer_list = np.ones(len(test_y))\n",
    "predict_df = pd.DataFrame(columns=[\"answer\", \"predict\", \"exact\"])\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for j, (X, label) in enumerate(zip(test_x, test_y)):\n",
    "        y = model(X)\n",
    "        predict = torch.argmax(y).to(\"cpu\")\n",
    "        predict = np.array(predict)\n",
    "        predict_list[j] = predict \n",
    "        answer = np.array(label.item())\n",
    "        answer_list[j] = answer\n",
    "        exact = \"O\" if predict.item() == answer.item() else \"X\"\n",
    "        s = pd.Series([answer, predict, exact], index=predict_df.columns)\n",
    "        predict_df = predict_df.append(s, ignore_index=True)\n",
    "\n",
    "print(predict_df.value_counts(\"exact\"))\n",
    "print(predict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab73b2c4-e3d1-4f48-94d6-6b8ad9b7b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "report = classification_report(answer_list, predict_list,output_dict= True)\n",
    "pd_report = pd.DataFrame(report).transpose()\n",
    "pd_report.to_csv(\"data7/report.csv\")\n",
    "\n",
    "matrix = confusion_matrix(answer_list, predict_list)\n",
    "sns.heatmap(matrix, annot=True)\n",
    "plt.xlabel(\"pred\")\n",
    "plt.ylabel('true')\n",
    "plt.savefig(\"data7/confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9bcc8b-48af-463d-97d2-958c1562846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # label_0\n",
    "# TP0 = 0\n",
    "# FN0 = 0\n",
    "# FP0 = 0\n",
    "# TN0 = 0\n",
    "# for ans, pred in zip(predict_df[\"answer\"], predict_df[\"predict\"]):\n",
    "#     if (ans == 0 and pred == 0):\n",
    "#         TP0 += 1\n",
    "#     elif (ans == 0 and pred != 0):\n",
    "#         FN0 += 1\n",
    "#     elif (ans != 1 and pred == 0):\n",
    "#         FP0 += 1\n",
    "#     elif (ans != 0 and pred != 0):\n",
    "#         TN0 += 1\n",
    "\n",
    "        \n",
    "# label_0 = 0     \n",
    "# all_0 = (predict_df[\"answer\"] == 0).sum()\n",
    "\n",
    "# acc_0 = (TP0+TN0) / (TP0+TN0+FP0+FN0)\n",
    "\n",
    "# recall_0 = TP0 / (TP0+FN0)\n",
    "\n",
    "# pre_0 = TP0 / (TP0+FP0)\n",
    "\n",
    "# F_0 = (2*recall_0*pre_0) / (recall_0+pre_0)\n",
    "\n",
    "# score_0 = np.array([label_0, all_0, acc_0, recall_0, pre_0, F_0])\n",
    "# print(score_0)\n",
    "\n",
    "\n",
    "\n",
    "# # label_1\n",
    "# TP1 = 0\n",
    "# FN1 = 0\n",
    "# FP1 = 0\n",
    "# TN1 = 0\n",
    "# for ans, pred in zip(predict_df[\"answer\"], predict_df[\"predict\"]):\n",
    "#     if (ans == 1 and pred == 1):\n",
    "#         TP1 += 1\n",
    "#     elif (ans == 1 and pred != 1):\n",
    "#         FN1 += 1\n",
    "#     elif (ans != 1 and pred == 1):\n",
    "#         FP1 += 1\n",
    "#     elif (ans != 1 and pred != 1):\n",
    "#         TN1 += 1\n",
    "\n",
    "        \n",
    "# label_1 = 1    \n",
    "# all_1 = (predict_df[\"answer\"] == 1).sum()\n",
    "\n",
    "# acc_1 = (TP1+TN1) / (TP1+TN1+FP1+FN1)\n",
    "\n",
    "# recall_1 = TP1 / (TP1+FN1)\n",
    "\n",
    "# pre_1 = TP1 / (TP1+FP1)\n",
    "\n",
    "# F_1 = (2*recall_1*pre_1) / (recall_1+pre_1)\n",
    "\n",
    "# score_1 = np.array([label_1, all_1, acc_1, recall_1, pre_1, F_1])\n",
    "# print(score_1)\n",
    "\n",
    "\n",
    "\n",
    "# # # label_2\n",
    "# TP2 = 0\n",
    "# FN2 = 0\n",
    "# FP2 = 0\n",
    "# TN2 = 0\n",
    "# for ans, pred in zip(predict_df[\"answer\"], predict_df[\"predict\"]):\n",
    "#     if (ans == 2 and pred == 2):\n",
    "#         TP2 += 1\n",
    "#     elif (ans == 2 and pred != 2):\n",
    "#         FN2 += 1\n",
    "#     elif (ans != 2 and pred == 2):\n",
    "#         FP2 += 1\n",
    "#     elif (ans != 2 and pred != 2):\n",
    "#         TN2 += 1\n",
    "\n",
    "        \n",
    "# label_2 = 2     \n",
    "# all_2 = (predict_df[\"answer\"] == 2).sum()\n",
    "\n",
    "# acc_2 = (TP2+TN2) / (TP2+TN2+FP2+FN2)\n",
    "\n",
    "# recall_2 = TP2 / (TP2+FN2)\n",
    "\n",
    "# pre_2 = TP2 / (TP2+FP2)\n",
    "\n",
    "# F_2 = (2*recall_2*pre_2) / (recall_2+pre_2)\n",
    "\n",
    "# score_2 = np.array([label_2, all_2, acc_2, recall_2, pre_2, F_2])\n",
    "# print(score_2)\n",
    "\n",
    "\n",
    "# # # label_3\n",
    "# TP3 = 0\n",
    "# FN3 = 0\n",
    "# FP3 = 0\n",
    "# TN3 = 0\n",
    "# for ans, pred in zip(predict_df[\"answer\"], predict_df[\"predict\"]):\n",
    "#     if (ans == 3 and pred == 3):\n",
    "#         TP3 += 1\n",
    "#     elif (ans == 3 and pred != 3):\n",
    "#         FN3 += 1\n",
    "#     elif (ans != 3 and pred == 3):\n",
    "#         FP3 += 1\n",
    "#     elif (ans != 3 and pred != 3):\n",
    "#         TN3 += 1\n",
    "\n",
    "        \n",
    "# label_3 = 3    \n",
    "# all_3 = (predict_df[\"answer\"] == 3).sum()\n",
    "\n",
    "# acc_3 = (TP3+TN3) / (TP3+TN3+FP3+FN3)\n",
    "\n",
    "# recall_3 = TP3 / (TP3+FN3)\n",
    "\n",
    "# pre_3 = TP3 / (TP3+FP3)\n",
    "\n",
    "# F_3 = (2*recall_3*pre_3) / (recall_3+pre_3)\n",
    "\n",
    "# score_3 = np.array([label_3, all_3, acc_3, recall_3, pre_3, F_3])\n",
    "# print(score_3)\n",
    "\n",
    "# score_df = pd.DataFrame(np.vstack((score_0, score_1)),\n",
    "#                        columns=[\"label\", \"all\", \"accuracy\", \"recall\", \"precision\", \"F-Score\"])\n",
    "# print(score_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shimalab",
   "language": "python",
   "name": "shimalab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
